{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('Pointnet_Pointnet2_pytorch')\n",
    "sys.path.append('Pointnet_Pointnet2_pytorch/models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def create_obb_from_description(centroid, dimensions, rotations):\n",
    "    # Extract centroid, dimensions, and rotations\n",
    "    cx, cy, cz = centroid\n",
    "    length, width, height = dimensions\n",
    "    rx, ry, rz = rotations * 360\n",
    "\n",
    "    # Create the 8 corners of the box before rotation and translation\n",
    "    dx = length / 2\n",
    "    dy = width / 2\n",
    "    dz = height / 2\n",
    "\n",
    "    corners = np.array([\n",
    "        [-dx, -dy, -dz],\n",
    "        [ dx, -dy, -dz],\n",
    "        [ dx,  dy, -dz],\n",
    "        [-dx,  dy, -dz],\n",
    "        [-dx, -dy,  dz],\n",
    "        [ dx, -dy,  dz],\n",
    "        [ dx,  dy,  dz],\n",
    "        [-dx,  dy,  dz]\n",
    "    ])\n",
    "\n",
    "    # Apply rotations\n",
    "    rotation = R.from_euler('xyz', [rx, ry, rz], degrees=True)\n",
    "    rotated_corners = rotation.apply(corners)\n",
    "\n",
    "    # Apply translation (centroid)\n",
    "    translated_corners = rotated_corners + np.array([cx, cy, cz])\n",
    "\n",
    "    return translated_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_rotation_matrix():\n",
    "    \"\"\"Generate a random 3D rotation matrix.\"\"\"\n",
    "    angle_x = np.random.uniform(0, 2 * np.pi)\n",
    "    angle_y = np.random.uniform(0, 2 * np.pi)\n",
    "    angle_z = np.random.uniform(0, 2 * np.pi)\n",
    "\n",
    "    Rx = np.array(\n",
    "        [\n",
    "            [1, 0, 0],\n",
    "            [0, np.cos(angle_x), -np.sin(angle_x)],\n",
    "            [0, np.sin(angle_x), np.cos(angle_x)],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    Ry = np.array(\n",
    "        [\n",
    "            [np.cos(angle_y), 0, np.sin(angle_y)],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(angle_y), 0, np.cos(angle_y)],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    Rz = np.array(\n",
    "        [\n",
    "            [np.cos(angle_z), -np.sin(angle_z), 0],\n",
    "            [np.sin(angle_z), np.cos(angle_z), 0],\n",
    "            [0, 0, 1],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    R = Rz @ Ry @ Rx  # Combined rotation matrix\n",
    "    return R\n",
    "\n",
    "\n",
    "def apply_rotation(point_cloud, bounding_box, rotation_matrix):\n",
    "    \"\"\"Apply rotation to a point cloud and bounding box.\n",
    "    ---------------\n",
    "    Params:\n",
    "    - point_cloud: Nx3 numpy array\n",
    "    - bounding_box: tuple containing the bounding box parameters:\n",
    "        - cx, cy, cz: center of the bounding box\n",
    "        - sidex, sidey, sidez: dimensions of the bounding box\n",
    "        - sin_rx, cos_rx, sin_ry, cos_ry, sin_rz, cos_rz: rotation parameters\n",
    "    \"\"\"\n",
    "    # Rotate the point cloud\n",
    "    rotated_point_cloud = deepcopy(point_cloud) @ rotation_matrix.T\n",
    "\n",
    "    # Extract bounding box parameters\n",
    "    cx, cy, cz, sidex, sidey, sidez, sin_rx, cos_rx, sin_ry, cos_ry, sin_rz, cos_rz = (\n",
    "        deepcopy(bounding_box)\n",
    "    )\n",
    "\n",
    "    # Rotate the center of the bounding box\n",
    "    bbox_center = np.array([cx, cy, cz])\n",
    "    rotated_bbox_center = bbox_center @ rotation_matrix.T\n",
    "\n",
    "    # Define the initial rotation matrix for the bounding box using the sine and cosine values\n",
    "    initial_rotation_matrix = np.array(\n",
    "        [\n",
    "            [\n",
    "                cos_ry * cos_rz,\n",
    "                cos_rz * sin_rx * sin_ry - cos_rx * sin_rz,\n",
    "                cos_rx * cos_rz * sin_ry + sin_rx * sin_rz,\n",
    "            ],\n",
    "            [\n",
    "                cos_ry * sin_rz,\n",
    "                cos_rx * cos_rz + sin_rx * sin_ry * sin_rz,\n",
    "                -cos_rz * sin_rx + cos_rx * sin_ry * sin_rz,\n",
    "            ],\n",
    "            [-sin_ry, cos_ry * sin_rx, cos_rx * cos_ry],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Combine the rotations: first the initial rotation, then the new rotation\n",
    "    combined_rotation_matrix = rotation_matrix @ initial_rotation_matrix\n",
    "\n",
    "    # Extract the new sine and cosine values from the combined rotation matrix\n",
    "    sin_rx = np.sin(\n",
    "        np.arctan2(combined_rotation_matrix[2, 1], combined_rotation_matrix[2, 2])\n",
    "    )\n",
    "    cos_rx = np.cos(\n",
    "        np.arctan2(combined_rotation_matrix[2, 1], combined_rotation_matrix[2, 2])\n",
    "    )\n",
    "    sin_ry = np.sin(\n",
    "        np.arctan2(\n",
    "            -combined_rotation_matrix[2, 0],\n",
    "            np.sqrt(\n",
    "                combined_rotation_matrix[2, 1] ** 2\n",
    "                + combined_rotation_matrix[2, 2] ** 2\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    cos_ry = np.cos(\n",
    "        np.arctan2(\n",
    "            -combined_rotation_matrix[2, 0],\n",
    "            np.sqrt(\n",
    "                combined_rotation_matrix[2, 1] ** 2\n",
    "                + combined_rotation_matrix[2, 2] ** 2\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    sin_rz = np.sin(\n",
    "        np.arctan2(combined_rotation_matrix[1, 0], combined_rotation_matrix[0, 0])\n",
    "    )\n",
    "    cos_rz = np.cos(\n",
    "        np.arctan2(combined_rotation_matrix[1, 0], combined_rotation_matrix[0, 0])\n",
    "    )\n",
    "\n",
    "    # Create the rotated bounding box\n",
    "    rotated_bounding_box = np.array([\n",
    "        rotated_bbox_center[0],\n",
    "        rotated_bbox_center[1],\n",
    "        rotated_bbox_center[2],\n",
    "        sidex,\n",
    "        sidey,\n",
    "        sidez,\n",
    "        sin_rx,\n",
    "        cos_rx,\n",
    "        sin_ry,\n",
    "        cos_ry,\n",
    "        sin_rz,\n",
    "        cos_rz,\n",
    "    ])\n",
    "\n",
    "    return rotated_point_cloud, rotated_bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sincos_to_angle(sin_val, cos_val):\n",
    "    angle = torch.atan2(sin_val, cos_val)  # Get the angle in radians\n",
    "    angle = angle % (2 * np.pi)  # Ensure the angle is in the range [0, 2*pi)\n",
    "    angle = angle / (2 * np.pi)  # Scale to [0, 1]\n",
    "    return angle.numpy()\n",
    "\n",
    "def angles_to_sincos(angles):\n",
    "    sin_angles = torch.sin(angles * 2 * np.pi)  # Assuming angles are scaled between 0 and 1\n",
    "    cos_angles = torch.cos(angles * 2 * np.pi)\n",
    "    return np.array([sin_angles.numpy(), cos_angles.numpy()])\n",
    "\n",
    "def normalize_point_cloud_and_obb(point_cloud, obb):\n",
    "    \"\"\"\n",
    "    Normalize the point cloud and the relative oriented bounding box (OBB).\n",
    "    \n",
    "    Parameters:\n",
    "    point_cloud (np.ndarray): The point cloud as an array of shape (N, 3).\n",
    "    obb_vertices (np.ndarray): OBB is centroid, dimensions, and rotations. (3, 3, 3)\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The normalized point cloud.\n",
    "    np.ndarray: The normalized OBB, rotations are scaled between 0 and 1\n",
    "    \"\"\"\n",
    "    # Calculate the centroid of the point cloud\n",
    "    centroid = np.mean(point_cloud, axis=0)\n",
    "    obb_centroid = obb[:3]\n",
    "    obb_dimensions = obb[3:6]\n",
    "    obb_rotations = obb[6:]\n",
    "    # Center the OBB vertices and point cloud points at the origin\n",
    "    \n",
    "    centered_pc = point_cloud - centroid\n",
    "    obb_centroid = obb_centroid - centroid\n",
    "    # Calculate the maximum distance from the origin for the point cloud points\n",
    "    max_distance = np.max(np.linalg.norm(centered_pc, axis=1))\n",
    "    \n",
    "    # Scale the OBB vertices and point cloud points\n",
    "    scaled_pc = centered_pc / max_distance\n",
    "    scaled_obb_centroid = obb_centroid / max_distance\n",
    "    scaled_obb_dimensions = obb_dimensions / max_distance\n",
    "    scaled_obb_rotations = obb_rotations / 360\n",
    "\n",
    "    sin_cos_rx = angles_to_sincos(torch.tensor(scaled_obb_rotations[0]))\n",
    "    sin_cos_ry = angles_to_sincos(torch.tensor(scaled_obb_rotations[1]))\n",
    "    sin_cos_rz = angles_to_sincos(torch.tensor(scaled_obb_rotations[2]))\n",
    "    scaled_obb_rotations = np.concatenate([sin_cos_rx, sin_cos_ry, sin_cos_rz])\n",
    "    scaled_obb = np.concatenate([scaled_obb_centroid, scaled_obb_dimensions, scaled_obb_rotations])\n",
    "\n",
    "    \n",
    "    return scaled_pc, scaled_obb, max_distance, centroid\n",
    "\n",
    "def denormalize_point_cloud_and_obb(normalized_pc, normalized_obb, max_distance, original_centroid):\n",
    "    \"\"\"\n",
    "    Denormalize the point cloud and the relative oriented bounding box (OBB).\n",
    "    \n",
    "    Parameters:\n",
    "    normalized_pc (np.ndarray): The normalized point cloud as an array of shape (N, 3).\n",
    "    normalized_obb (np.ndarray): The normalized OBB, rotations are scaled between 0 and 1.\n",
    "    max_distance (float): The maximum distance used for normalization.\n",
    "    original_centroid (np.ndarray): The original centroid of the point cloud.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The denormalized point cloud.\n",
    "    np.ndarray: The denormalized OBB.\n",
    "    \"\"\"\n",
    "    # Extract normalized OBB components\n",
    "    normalized_obb_centroid = deepcopy(normalized_obb[:3])\n",
    "    normalized_obb_dimensions = deepcopy(normalized_obb[3:6])\n",
    "    \n",
    "    sin_cos_rx = torch.tensor(deepcopy(normalized_obb[6:8]))\n",
    "    sin_cos_ry = torch.tensor(deepcopy(normalized_obb[8:10]))\n",
    "    sin_cos_rz = torch.tensor(deepcopy(normalized_obb[10:12]))\n",
    "    \n",
    "    # Convert sin and cos back to angles\n",
    "    denorm_rx = sincos_to_angle(sin_cos_rx[0], sin_cos_rx[1])\n",
    "    denorm_ry = sincos_to_angle(sin_cos_ry[0], sin_cos_ry[1])\n",
    "    denorm_rz = sincos_to_angle(sin_cos_rz[0], sin_cos_rz[1])\n",
    "    \n",
    "    denorm_rotations = np.array([denorm_rx, denorm_ry, denorm_rz]) #* 360\n",
    "    \n",
    "    # Denormalize the point cloud and OBB components\n",
    "    denorm_pc = normalized_pc * max_distance + original_centroid\n",
    "    denorm_obb_centroid = normalized_obb_centroid * max_distance + original_centroid\n",
    "    denorm_obb_dimensions = normalized_obb_dimensions * max_distance\n",
    "    \n",
    "    denorm_obb = np.concatenate([denorm_obb_centroid, denorm_obb_dimensions, denorm_rotations])\n",
    "    \n",
    "    return denorm_pc, denorm_obb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open('gt_dataset2.json'))\n",
    "for obj in dataset:\n",
    "    dataset[obj]['points'] = np.array(dataset[obj]['points']).reshape(-1, 3)\n",
    "    dataset[obj]['box'] = np.array(dataset[obj]['box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize input and output data\n",
    "min_rot, max_rot = np.inf, -np.inf\n",
    "for obj in dataset.values():\n",
    "   rotations = obj['box'][6:]\n",
    "   obj['points'], obj['box'], obj['max_distance'], obj['centroid'] = normalize_point_cloud_and_obb(obj['points'], obj['box'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(list(dataset.keys())[-1]) + 1\n",
    "to_append = {}\n",
    "for obj in dataset.values():\n",
    "    for _ in range(3):\n",
    "        rotated_pc, rotated_box = apply_rotation(obj['points'], obj['box'], generate_random_rotation_matrix())\n",
    "        max_distance = max_distance = np.max(np.linalg.norm(rotated_pc, axis=1))\n",
    "        centroid = np.mean(rotated_pc, axis=0)\n",
    "        to_append[index] = {'points': rotated_pc, 'box': rotated_box, 'max_distance': max_distance, 'centroid': centroid}\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.update(to_append)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = list(dataset.values())\n",
    "        self.maxpoints = max([len(obj['points']) for obj in self.dataset])\n",
    "        self.centroid = [obj['centroid'] for obj in self.dataset]\n",
    "        self.max_distance = [obj['max_distance'] for obj in self.dataset]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        points = torch.tensor(self.dataset[idx]['points'], dtype = torch.float32)\n",
    "        if points.shape[0] > 1024:\n",
    "            points = points[torch.randperm(points.shape[0])[:1024]]\n",
    "        if points.shape[0] < 1024:\n",
    "            points = torch.cat([points, torch.zeros(1024 - len(points), 3)])\n",
    "        assert points.shape[0] == 1024\n",
    "        \n",
    "        #points = torch.cat([points, torch.zeros(self.maxpoints - len(points), 3)])\n",
    "        points = points.permute(1, 0)\n",
    "        box = torch.tensor(self.dataset[idx]['box'], dtype = torch.float32).unsqueeze(0)\n",
    "        return points, box, self.max_distance[idx], self.centroid[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(points, box):\n",
    "    centroid = box[0][:3]\n",
    "    dimensions = box[0][3:6]\n",
    "    rotations = box[0][6:]\n",
    "    rx = sincos_to_angle(rotations[0], rotations[1])\n",
    "    ry = sincos_to_angle(rotations[2], rotations[3])\n",
    "    rz = sincos_to_angle(rotations[4], rotations[5])\n",
    "    box = create_obb_from_description(centroid, dimensions, np.array([rx, ry, rz]))\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points.permute(1, 0).numpy())\n",
    "    box = o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(box))\n",
    "    box.color = (1, 0, 0)\n",
    "    o3d.visualization.draw_geometries([pcd, box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw(*Dataset(dataset)[20][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 82)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = Dataset(dataset)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 201\n",
    "sample = data[idx]\n",
    "pc = sample[0]\n",
    "box = sample[1]\n",
    "max_distance = sample[2]\n",
    "centroid = sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pc.permute(1, 0).numpy()\n",
    "box = box.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_pc, rotated_box = apply_rotation(pc, box[0], generate_random_rotation_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1024]), torch.Size([1, 12]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_pc = torch.tensor(rotated_pc).permute(1, 0)\n",
    "rotated_box = torch.tensor(rotated_box).unsqueeze(0)\n",
    "rotated_pc.shape, rotated_box.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(data[idx][0], data[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(rotated_pc, rotated_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'permute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/nicoloagostara/catkin_ws/src/s_map/notebooks/box_estimation/bbox_estimation.ipynb Cella 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nicoloagostara/catkin_ws/src/s_map/notebooks/box_estimation/bbox_estimation.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m denormalized_pc, denormalized_box \u001b[39m=\u001b[39m denormalize_point_cloud_and_obb(pc\u001b[39m.\u001b[39;49mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mnumpy(), box[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy(), max_distance, centroid)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'permute'"
     ]
    }
   ],
   "source": [
    "denormalized_pc, denormalized_box = denormalize_point_cloud_and_obb(pc.permute(1, 0).numpy(), box[0].numpy(), max_distance, centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.09201974,  0.13136518, -0.16020407,  0.80898261,  0.77780479,\n",
       "         1.35952616,  0.06569515,  0.89122862,  0.24758725]),\n",
       " tensor([[-0.0920,  0.1314, -0.1602,  0.8090,  0.7778,  1.3595,  0.4012,  0.9160,\n",
       "          -0.6315,  0.7754,  0.9999,  0.0152]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denormalized_box, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(denormalized_pc)\n",
    "pcd.paint_uniform_color([1, 0, 0])\n",
    "centroid, dimensions, rotations = (\n",
    "    deepcopy(denormalized_box[:3]),\n",
    "    deepcopy(denormalized_box[3:6]),\n",
    "    deepcopy(denormalized_box[6:]),\n",
    ")\n",
    "box = create_obb_from_description(centroid, dimensions, rotations)\n",
    "box = o3d.geometry.OrientedBoundingBox.create_from_points(\n",
    "    o3d.utility.Vector3dVector(box)\n",
    ")\n",
    "box.color = (1, 0, 0)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd, box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 12])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Pointnet_Pointnet2_pytorch.models.pointnet_utils import PointNetEncoder\n",
    "class PointCloudNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointCloudNet, self).__init__()\n",
    "        self.backbone = PointNetEncoder(global_feat=True, feature_transform=False, channel = 3)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x[0]\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 1, 12)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, num_epochs, optimizer, criterion, train_loader, test_loader, device):\n",
    "        best_val_loss = np.inf\n",
    "        pbar = tqdm(range(num_epochs))\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                points, box, _, _ = data                \n",
    "                points, box = points.to(device), box.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, box)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            train_loss = running_loss / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            for data in test_loader:\n",
    "                points, box, _, _ = data\n",
    "                points, box = points.to(device), box.to(device)\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, box)\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            val_loss = running_loss / len(test_loader)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), \"pc_net.pth\")\n",
    "            \n",
    "            pbar.set_postfix({'train_loss': train_loss, 'val_loss': val_loss, 'best_val_loss': best_val_loss})\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model = PointCloudNet()\n",
    "model.to(device)\n",
    "model.train()\n",
    "x = torch.randn(10, 3, 120, device = device)\n",
    "model(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 12])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EasyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EasyNet, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 1, 12)\n",
    "        return x\n",
    "    def train_model(self, num_epochs, optimizer, criterion, train_loader, test_loader, device):\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(train_loader):\n",
    "                points, box, _, _ = data                \n",
    "                points, box = points.to(device), box.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, box)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch} - Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "                model.eval()\n",
    "                running_loss = 0.0\n",
    "                for i, data in enumerate(tqdm(test_loader)):\n",
    "                    points, box, _, _ = data\n",
    "                    points, box = points.to(device), box.to(device)\n",
    "                    outputs = model(points)\n",
    "                    loss = criterion(outputs, box)\n",
    "                    running_loss += loss.item()\n",
    "                print(f\"Validation Loss: {running_loss / len(test_loader)}\")\n",
    "\n",
    "model = EasyNet()\n",
    "model.to(device)\n",
    "model.train()\n",
    "x = torch.randn(10, 3, 1024, device = device)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 12])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
    "from Pointnet_Pointnet2_pytorch.models.pointnet2_cls_ssg import get_model\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self,normal_channel=True):\n",
    "        super(Backbone, self).__init__()\n",
    "        in_channel = 6 if normal_channel else 3\n",
    "        self.normal_channel = normal_channel\n",
    "        self.sa1 = PointNetSetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)\n",
    "        self.sa2 = PointNetSetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)\n",
    "        self.sa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)\n",
    "    \n",
    "    def forward(self, xyz):\n",
    "        B, _, _ = xyz.shape\n",
    "        if self.normal_channel:\n",
    "            norm = xyz[:, 3:, :]\n",
    "            xyz = xyz[:, :3, :]\n",
    "        else:\n",
    "            norm = None\n",
    "        l1_xyz, l1_points = self.sa1(xyz, norm)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        x = l3_points.view(B, 1024)\n",
    "        return x\n",
    "\n",
    "def load_backbone():\n",
    "    state_dict = \"Pointnet_Pointnet2_pytorch/log/classification/pointnet2_ssg_wo_normals/checkpoints/best_model.pth\"\n",
    "    d = torch.load(state_dict, map_location='cpu')['model_state_dict']\n",
    "    model = Backbone(normal_channel=False)\n",
    "    for key in d:\n",
    "        if key in model.state_dict():\n",
    "            model.state_dict()[key] = d[key]\n",
    "\n",
    "    return model\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = load_backbone()\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fc = nn.Linear(1024, 12)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 1, 12)\n",
    "        return x\n",
    "    \n",
    "    def train_model(self, num_epochs, optimizer, criterion, train_loader, test_loader, device):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(tqdm(train_loader)):\n",
    "                points, box, _, _ = data                \n",
    "                points, box = points.to(device), box.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, box)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch} - Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(tqdm(test_loader)):\n",
    "                points, box, _, _ = data\n",
    "                points, box = points.to(device), box.to(device)\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, box)\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            if running_loss < best_val_loss:\n",
    "                best_val_loss = running_loss\n",
    "                torch.save(model.state_dict(), \"best_model2.pth\")\n",
    "            print(f\"Validation Loss: {running_loss / len(test_loader)}\")\n",
    "\n",
    "x = torch.randn(10, 3, 1024)\n",
    "model = Model()\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:25<00:00,  1.38it/s, train_loss=67.1, val_loss=40.2, best_val_loss=39]  \n"
     ]
    }
   ],
   "source": [
    "# Define the regression loss function\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "# Initialize the model, optimizer, and criterion\n",
    "model = PointCloudNet()\n",
    "device = torch.device(\"mps\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "model = model.to(device)\n",
    "\n",
    "# Example training loop\n",
    "num_epochs = 200\n",
    "model.train_model(num_epochs, optimizer, criterion, train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PointCloudNet()\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"pc_net.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(points, gt_box, pred_box):\n",
    "    centroid = deepcopy(gt_box[0][:3])\n",
    "    dimensions = deepcopy(gt_box[0][3:6])\n",
    "    rotations = deepcopy(gt_box[0][6:])\n",
    "    rx = sincos_to_angle(rotations[0], rotations[1])\n",
    "    ry = sincos_to_angle(rotations[2], rotations[3])\n",
    "    rz = sincos_to_angle(rotations[4], rotations[5])\n",
    "    gt_box = create_obb_from_description(centroid, dimensions, np.array([rx, ry, rz]))\n",
    "\n",
    "    pred_box = deepcopy(pred_box[0])\n",
    "    centroid = deepcopy(pred_box[:3])\n",
    "    dimensions = deepcopy(pred_box[3:6])\n",
    "    rotations = deepcopy(pred_box[6:])\n",
    "    rx = sincos_to_angle(rotations[0], rotations[1])\n",
    "    ry = sincos_to_angle(rotations[2], rotations[3])\n",
    "    rz = sincos_to_angle(rotations[4], rotations[5])\n",
    "    pred_box = create_obb_from_description(centroid, dimensions, np.array([rx, ry, rz]))\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    gt_box = o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(gt_box))\n",
    "    gt_box.color = (1, 0, 0)\n",
    "\n",
    "    pred_box = o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(pred_box))\n",
    "    pred_box.color = (0, 1, 0)\n",
    "    o3d.visualization.draw_geometries([pcd, gt_box, pred_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, box, max_distance, centroid = next(iter(test_loader))\n",
    "idx = 5\n",
    "model.eval()\n",
    "sample_pc = points[idx].permute(1, 0).numpy()\n",
    "sample_box = box[idx]\n",
    "\n",
    "pred_box = model(points.to(device))[idx].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-5.3533e-03,  1.9682e-02, -2.0012e-02,  1.2397e+00,  8.5698e-01,\n",
       "           1.4516e+00,  5.5624e-02,  2.2031e-01, -9.2282e-04,  7.7289e-01,\n",
       "           1.4975e-01,  1.7810e-01]]),\n",
       " tensor([[ 0.0286, -0.2116, -0.0687,  1.0836,  0.6205,  1.6926, -0.5067,  0.8621,\n",
       "           0.6622,  0.7493,  0.7698,  0.6383]]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_box, sample_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(sample_pc, sample_box, pred_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0226,  0.3352, -0.0308,  1.2851,  0.1802,  0.6912,  0.0000,  1.0000,\n",
       "          0.0133,  0.9999,  0.9980,  0.0629]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
